{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1974,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from pandas.io.json import json_normalize \n",
    "from pandas import read_csv\n",
    "import logging\n",
    "from functools import reduce\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1756,
   "metadata": {},
   "outputs": [],
   "source": [
    "#etl = 'kobo2elastic'\n",
    "etl = 'curis2elastic'\n",
    "#etl = 'oldcuris2newcuris'\n",
    "\n",
    "input_schema_file = ''\n",
    "input_data_file = ''\n",
    "mapping_file = ''\n",
    "    \n",
    "if etl == 'curis2elastic':\n",
    "    #old curis to elasticsearch\n",
    "    input_schema_file = 'schema/input/curisSchema.1-item.json'\n",
    "    input_data_file = 'data/curisData.1-items.json'\n",
    "    mapping_file = 'schema/map/couchbase2elastic.map.csv'\n",
    "elif etl == 'kobo2elastic':\n",
    "    #kobo to elasticsearch\n",
    "    input_schema_file = 'schema/input/aqmSchema.complete.json'\n",
    "    input_data_file = 'data/aqmData.2-items.json'\n",
    "    mapping_file = 'schema/map/kobo2elastic.map.csv'\n",
    "elif etl == 'oldcuris2newcuris':\n",
    "    #kobo to elasticsearch\n",
    "    input_schema_file = 'schema/input/curisData.1-Schema.avro.json'\n",
    "    input_data_file = 'data/curisData.1-items.json'\n",
    "    mapping_file = 'schema/map/kobo2elastic.map.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create separate CSV files based on array types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>birthdate</th>\n",
       "      <th>family_members</th>\n",
       "      <th>first_name</th>\n",
       "      <th>gender</th>\n",
       "      <th>id</th>\n",
       "      <th>last_name</th>\n",
       "      <th>last_name_suffix</th>\n",
       "      <th>middle_name</th>\n",
       "      <th>nhid</th>\n",
       "      <th>organization</th>\n",
       "      <th>registered_at</th>\n",
       "      <th>type</th>\n",
       "      <th>identification.id2.type</th>\n",
       "      <th>user-cam.id</th>\n",
       "      <th>user-cam.owner</th>\n",
       "      <th>profile_picture.path</th>\n",
       "      <th>identification.id3.type</th>\n",
       "      <th>identification.id1.type</th>\n",
       "      <th>profile_picture.name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [birthdate, family_members, first_name, gender, id, last_name, last_name_suffix, middle_name, nhid, organization, registered_at, type, identification.id2.type, user-cam.id, user-cam.owner, profile_picture.path, identification.id3.type, identification.id1.type, profile_picture.name]\n",
       "Index: []"
      ]
     },
     "execution_count": 2242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_resident_df  = pd.DataFrame(columns = main_header_list)\n",
    "#main_resident_df = main_resident_df.iloc[0:0]\n",
    "#main_resident_df\n",
    "#main_resident_df.columns = main_header\n",
    "\n",
    "#TODO: check if header/columns already exist\n",
    "main_resident_df.to_csv('file/resident.csv', encoding='utf-8', mode='a', index=False)\n",
    "main_resident_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split ang get first string, \n",
    "### if string is equal to csv filename, include as csv header in same csv filename\n",
    "### if string not equal, include as csv header in main csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = []\n",
    "headers =  list(csv_header_name_df['source_key'])\n",
    "\n",
    "empty_df = pd.DataFrame()\n",
    "empty_df.columns = [\"Sequence\", \"Start\", \"End\", \"Coverage\"]\n",
    "#empty_df.to_csv('file/resident.csv', encoding='utf-8', mode='a', header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#df.to_csv('file/resident.csv', encoding='utf-8', mode='w', header=header, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = []\n",
    "with open(input_data_file) as f:\n",
    "    #d = json.load(f)\n",
    "    d = json.load(f)\n",
    "    print('----')\n",
    "    print(d)\n",
    "    print('---type--')\n",
    "print(type(d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "flat_json_0 = {}\n",
    "flat_json_1 = {}\n",
    "flat_json_2 = {}\n",
    "\n",
    "flat_json_0 = flattenDict(d[0])\n",
    "print('--flatten_dict_type--')\n",
    "print(type(flat_json_0))\n",
    "print('--flatten_dict_data--')\n",
    "flat_json_0\n",
    "\n",
    "print('--normalize flatten_dict--')\n",
    "json_flat_norm_0 = json_normalize(flat_json_0)\n",
    "\n",
    "\n",
    "flat_json_1 = flattenDict(d[1])\n",
    "json_flat_norm_1 = json_normalize(flat_json_1)\n",
    "\n",
    "flat_json_2 = flattenDict(d[2])\n",
    "json_flat_norm_2 = json_normalize(flat_json_2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_flat_norm_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_flat_norm_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_flat_norm_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TESTING: flattendict with nested array of objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dx = []\n",
    "dx = {}\n",
    "dx_list = []\n",
    "dx_dict = {}\n",
    "dx_normalize_df = pd.DataFrame()\n",
    "\n",
    "input_data_file_test = 'data/curisData.1-items.json'\n",
    "with open(input_data_file_test) as f:\n",
    "    dx_list = json.load(f)\n",
    "    #dx = json.load(f)\n",
    "\n",
    "type(dx_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dx_flatten = flatten_json(dx_list[0])\n",
    "dx_flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dx_normalize_df = json_normalize(dx_flatten)\n",
    "\n",
    "dx_normalize_df.T.to_csv('processed_data.csv',sep=',')\n",
    "type(dx_normalize_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(dx_normalize_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dx_normalize_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: ITERATE OVER LIST and MERGE normalize headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_df = pd.DataFrame()\n",
    "input_data_df = json_flat_norm_0\n",
    "input_data_df = input_data_df.append(json_flat_norm_1, sort=True)\n",
    "input_data_df = input_data_df.append(json_flat_norm_2, sort=True)\n",
    "input_data_df.sort_values(['demographics.awh_id']).reset_index(drop=True)\n",
    "#input_data_df.sort_values(p'd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(input_data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean input data column header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_df.columns = input_data_df.columns.str.lower().str.replace('/','.')\n",
    "input_data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Mapping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_df = pd.read_csv(mapping_file, skiprows=0)\n",
    "mapping_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get values input data that are included mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_data_df = pd.DataFrame()\n",
    "selected_data_df = input_data_df[list(mapping_df['source_key'])]\n",
    "selected_data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Renamce source header fields into destination header fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_data_df.columns = list(mapping_df['destination_key'])\n",
    "selected_data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode to as Filesystem (HDFS) or S3 (avro) format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decode for cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decode to for computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decode to for analytics transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform flat file into output schema format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_json = ''\n",
    "flat_json = selected_data_df.to_json(orient='records')\n",
    "json_json = json.loads(flat_json)\n",
    "json_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert dot notated fields into nested json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = 'data/data.json'\n",
    "with open(input_file) as f:\n",
    "    d = (f)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def dot_to_json(a):\n",
    "    output = {}\n",
    "    for key, value in a.items():\n",
    "        path = key.split('.')[1:]  # ignore the json. prefix\n",
    "        #path = key\n",
    "        target = reduce(lambda d, k: d.setdefault(k, {}), path[:-1], output)\n",
    "        target[path[-1]] = value\n",
    "    return output\n",
    " \n",
    "data = {'json.message.status.time':50, 'json.message.code.response':80, 'json.time':100}\n",
    "type(data)\n",
    "\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dot data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_json = dot_to_json(data)\n",
    "dict_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dictionary to json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _dict2json(results):\n",
    "    counter = 0\n",
    "    data = []\n",
    "\n",
    "    for row in results: \n",
    "        data.append(json.dumps(row))\n",
    "        counter += 1\n",
    "    \n",
    "    return data\n",
    "\n",
    "json_dict = _dict2json(dict_json) \n",
    "json_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = pd.DataFrame()\n",
    "iris = pd.read_csv('data/sql.csv')\n",
    "iris\n",
    "#iris.to_json(orient='records')\n",
    "list(iris['0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
